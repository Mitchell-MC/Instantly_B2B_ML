"""
CI/CD Pipeline Demo
Demonstrates the comprehensive CI/CD pipeline capabilities for ML models.
"""

import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import logging
import warnings
warnings.filterwarnings('ignore')

# Add src directory to Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def demo_cicd_pipeline():
    """Demonstrate CI/CD pipeline capabilities."""
    print("ğŸš€ CI/CD Pipeline Implementation")
    print("="*80)
    
    # Step 1: Initialize CI/CD Pipeline
    print("\nğŸ“Š Step 1: Initializing CI/CD Pipeline")
    print("-" * 50)
    
    try:
        from cicd_pipeline import CICDPipeline
        pipeline = CICDPipeline()
        print("âœ… CI/CD Pipeline initialized successfully")
    except Exception as e:
        print(f"âŒ Failed to initialize CI/CD pipeline: {e}")
        return None
    
    # Step 2: Create a Sample Model for Testing
    print("\nğŸ“Š Step 2: Creating Sample Model for Testing")
    print("-" * 50)
    
    try:
        # Create a simple model for demonstration
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.datasets import make_classification
        import joblib
        
        # Create sample data
        X, y = make_classification(n_samples=100, n_features=5, n_classes=2, random_state=42)
        
        # Train a simple model
        model = RandomForestClassifier(n_estimators=10, random_state=42)
        model.fit(X, y)
        
        # Save the model
        model_path = "models/sample_model.joblib"
        os.makedirs("models", exist_ok=True)
        joblib.dump(model, model_path)
        
        print(f"âœ… Sample model created and saved to: {model_path}")
        print(f"   Model type: {type(model).__name__}")
        print(f"   Features: {X.shape[1]}")
        print(f"   Samples: {X.shape[0]}")
        
    except Exception as e:
        print(f"âŒ Failed to create sample model: {e}")
        return None
    
    # Step 3: Run CI/CD Pipeline (Testing Only)
    print("\nğŸ“Š Step 3: Running CI/CD Pipeline (Testing Only)")
    print("-" * 50)
    
    try:
        print("ğŸ§ª Running pipeline with testing stages only...")
        pipeline_result = pipeline.run_pipeline(
            model_path=model_path,
            environment='staging',
            auto_deploy=False  # Don't deploy automatically for demo
        )
        
        if pipeline_result:
            print(f"âœ… Pipeline completed with status: {pipeline_result['overall_status']}")
            print(f"   Pipeline ID: {pipeline_result['pipeline_id']}")
            print(f"   Execution Time: {pipeline_result.get('execution_time_seconds', 0):.2f} seconds")
            
            # Show stage results
            stages = pipeline_result.get('stages', {})
            for stage_name, stage_result in stages.items():
                status = stage_result.get('status', 'unknown')
                print(f"   {stage_name.title()}: {status}")
                
                # Show detailed results for testing stage
                if stage_name == 'testing' and status == 'passed':
                    test_details = stage_result.get('details', {})
                    print(f"     Unit Tests: {test_details.get('unit_tests', {}).get('tests_passed', 0)}/{test_details.get('unit_tests', {}).get('tests_run', 0)} passed")
                    print(f"     Integration Tests: {test_details.get('integration_tests', {}).get('tests_passed', 0)}/{test_details.get('integration_tests', {}).get('tests_run', 0)} passed")
                    print(f"     Performance Tests: {test_details.get('performance_tests', {}).get('tests_passed', 0)}/{test_details.get('performance_tests', {}).get('tests_run', 0)} passed")
                    print(f"     Overall Coverage: {stage_result.get('coverage', 0):.2%}")
                
                # Show validation results
                elif stage_name == 'validation' and status == 'passed':
                    print(f"     Model Performance: {stage_result.get('model_performance', {}).get('status', 'unknown')}")
                    print(f"     Data Quality: {stage_result.get('data_quality', {}).get('status', 'unknown')}")
                
                # Show security results
                elif stage_name == 'security':
                    risk_level = stage_result.get('overall_risk', 'unknown')
                    print(f"     Overall Risk: {risk_level}")
                    if risk_level == 'high':
                        print(f"     âš ï¸ Security issues detected!")
            
            # Show any errors or warnings
            if pipeline_result.get('errors'):
                print(f"\nğŸš¨ Pipeline Errors:")
                for error in pipeline_result['errors']:
                    print(f"   - {error}")
            
            if pipeline_result.get('warnings'):
                print(f"\nâš ï¸ Pipeline Warnings:")
                for warning in pipeline_result['warnings']:
                    print(f"   - {warning}")
                    
        else:
            print("âŒ Pipeline execution failed")
            
    except Exception as e:
        print(f"âŒ Pipeline execution failed: {e}")
    
    # Step 4: Run Full Pipeline with Deployment
    print("\nğŸ“Š Step 4: Running Full Pipeline with Deployment")
    print("-" * 50)
    
    try:
        print("ğŸš€ Running complete pipeline with deployment...")
        full_pipeline_result = pipeline.run_pipeline(
            model_path=model_path,
            environment='staging',
            auto_deploy=True  # Enable automatic deployment
        )
        
        if full_pipeline_result:
            print(f"âœ… Full pipeline completed with status: {full_pipeline_result['overall_status']}")
            
            # Check if deployment was successful
            deployment_stage = full_pipeline_result.get('stages', {}).get('deployment', {})
            if deployment_stage.get('status') == 'deployed':
                print("ğŸ‰ Model deployed successfully!")
                print(f"   Environment: {deployment_stage.get('environment', 'unknown')}")
                print(f"   Deployment Time: {deployment_stage.get('deployment_time', 'unknown')}")
                
                # Show health check results
                health_check = deployment_stage.get('health_check', {})
                if health_check.get('overall_status') == 'healthy':
                    print("   Health Check: âœ… PASSED")
                else:
                    print("   Health Check: âŒ FAILED")
                    
            elif deployment_stage.get('status') == 'rolled_back':
                print("ğŸ”„ Model deployment rolled back")
                print("   This indicates the new model failed health checks")
                
            else:
                print(f"   Deployment Status: {deployment_stage.get('status', 'unknown')}")
                
        else:
            print("âŒ Full pipeline execution failed")
            
    except Exception as e:
        print(f"âŒ Full pipeline execution failed: {e}")
    
    # Step 5: Pipeline Status and History
    print("\nğŸ“Š Step 5: Pipeline Status and History")
    print("-" * 50)
    
    try:
        status = pipeline.get_pipeline_status()
        print(f"ğŸ“Š Pipeline Status:")
        print(f"  Total Pipelines: {status.get('total_pipelines', 0)}")
        print(f"  Successful: {status.get('successful_pipelines', 0)}")
        print(f"  Failed: {status.get('failed_pipelines', 0)}")
        
        # Show recent pipelines
        recent_pipelines = status.get('recent_pipelines', [])
        if recent_pipelines:
            print(f"\nğŸ“‹ Recent Pipelines:")
            for i, recent in enumerate(recent_pipelines[-3:], 1):  # Show last 3
                pipeline_id = recent.get('pipeline_id', 'unknown')
                status = recent.get('overall_status', 'unknown')
                execution_time = recent.get('execution_time_seconds', 0)
                print(f"  {i}. {pipeline_id}: {status} ({execution_time:.2f}s)")
                
    except Exception as e:
        print(f"âŒ Failed to get pipeline status: {e}")
    
    # Step 6: Rollback Demonstration
    print("\nğŸ“Š Step 6: Rollback Demonstration")
    print("-" * 50)
    
    try:
        print("ğŸ”„ Demonstrating rollback capability...")
        
        # Check if we have a deployment to rollback
        deploy_dir = "models/staging"
        if os.path.exists(deploy_dir):
            model_files = [f for f in os.listdir(deploy_dir) if not f.endswith('.backup')]
            backup_files = [f for f in os.listdir(deploy_dir) if f.endswith('.backup')]
            
            if model_files and backup_files:
                print(f"   Current model: {model_files[0]}")
                print(f"   Available backups: {len(backup_files)}")
                
                # Demonstrate rollback (without actually doing it)
                print("   ğŸ’¡ Rollback capability verified")
                print("   ğŸ’¡ Use pipeline.rollback_deployment('staging') to rollback")
            else:
                print("   No deployment or backup files found")
        else:
            print("   No deployment directory found")
            
    except Exception as e:
        print(f"âŒ Rollback demonstration failed: {e}")
    
    # Step 7: MLOps Integration
    print("\nğŸ”— Step 7: MLOps Pipeline Integration")
    print("-" * 50)
    
    print("ğŸš€ CI/CD Pipeline integrates with:")
    print("  âœ… Data Quality Monitoring - Quality validation in pipeline")
    print("  âœ… Model Performance Tracking - Performance validation")
    print("  âœ… Drift Detection - Data drift validation")
    print("  âœ… Security Scanning - Vulnerability and secret detection")
    print("  âœ… Automated Testing - Unit, integration, and performance tests")
    print("  âœ… Health Checks - Post-deployment validation")
    print("  âœ… Rollback Mechanisms - Automatic rollback on failure")
    print("  âœ… External CI/CD Tools - GitHub Actions, Jenkins, etc.")
    
    # Step 8: Real-World Usage Examples
    print("\nğŸ’¡ Step 8: Real-World Usage Examples")
    print("-" * 50)
    
    print("ğŸš€ How to use in production:")
    print("\n1. Run Pipeline for New Model:")
    print("   pipeline.run_pipeline('path/to/model.joblib', 'production')")
    
    print("\n2. Run Pipeline with Validation Only:")
    print("   pipeline.run_pipeline('path/to/model.joblib', 'staging', auto_deploy=False)")
    
    print("\n3. Check Pipeline Status:")
    print("   status = pipeline.get_pipeline_status()")
    
    print("\n4. Rollback Failed Deployment:")
    print("   pipeline.rollback_deployment('production')")
    
    print("\n5. Integrate with External CI/CD:")
    print("   # Configure webhooks in config/main_config.yaml")
    print("   # Pipeline will send notifications to external systems")
    
    # Step 9: Pipeline Configuration
    print("\nâš™ï¸ Step 9: Pipeline Configuration")
    print("-" * 50)
    
    try:
        config = pipeline.config
        print("ğŸ“‹ Current Pipeline Configuration:")
        print(f"  Stages: {config.get('pipeline', {}).get('stages', [])}")
        print(f"  Timeout: {config.get('pipeline', {}).get('timeout_minutes', 0)} minutes")
        print(f"  Max Retries: {config.get('pipeline', {}).get('max_retries', 0)}")
        print(f"  Parallel Execution: {config.get('pipeline', {}).get('parallel_execution', False)}")
        
        print(f"\n  Testing Thresholds:")
        print(f"    Unit Tests: {config.get('testing', {}).get('unit_test_threshold', 0):.0%}")
        print(f"    Integration Tests: {config.get('testing', {}).get('integration_test_threshold', 0):.0%}")
        print(f"    Performance Tests: {config.get('testing', {}).get('performance_test_threshold', 0):.0%}")
        
        print(f"\n  Security Settings:")
        print(f"    Vulnerability Scan: {config.get('security', {}).get('vulnerability_scan', False)}")
        print(f"    Secrets Scan: {config.get('security', {}).get('secrets_scan', False)}")
        print(f"    Max Severity: {config.get('security', {}).get('max_severity', 'unknown')}")
        
    except Exception as e:
        print(f"âŒ Failed to show configuration: {e}")
    
    print("\nğŸ‰ CI/CD Pipeline Demo Complete!")
    print("="*80)
    
    return pipeline

def show_cicd_features():
    """Display the features of the CI/CD pipeline."""
    print("\nğŸš€ CI/CD PIPELINE FEATURES")
    print("="*80)
    
    print("ğŸ§ª AUTOMATED TESTING:")
    print("  âœ… Unit Tests: Model file validation and loading tests")
    print("  âœ… Integration Tests: Prediction interface validation")
    print("  âœ… Performance Tests: Loading and prediction performance")
    print("  âœ… Coverage Reporting: Test success rate tracking")
    
    print("\nâœ… MODEL VALIDATION:")
    print("  âœ… Performance Validation: Model performance metrics")
    print("  âœ… Data Quality Validation: Data quality metrics")
    print("  âœ… Drift Detection: Data drift validation")
    print("  âœ… Threshold Checking: Configurable validation thresholds")
    
    print("\nğŸ”’ SECURITY SCANNING:")
    print("  âœ… File Permissions: Security permission checks")
    print("  âœ… Secrets Detection: Hardcoded secret scanning")
    print("  âœ… Vulnerability Assessment: Security risk classification")
    print("  âœ… Risk Classification: Low/Medium/High risk levels")
    
    print("\nğŸš€ AUTOMATED DEPLOYMENT:")
    print("  âœ… Environment Management: Staging/Production support")
    print("  âœ… Health Checks: Post-deployment validation")
    print("  âœ… Rollback Mechanisms: Automatic rollback on failure")
    print("  âœ… Backup Management: Model version backup")
    
    print("\nğŸ“Š MONITORING & REPORTING:")
    print("  âœ… Pipeline History: Complete execution history")
    print("  âœ… Performance Metrics: Execution time tracking")
    print("  âœ… Error Reporting: Detailed error analysis")
    print("  âœ… Webhook Integration: External system notifications")
    
    print("\nğŸ”— EXTERNAL INTEGRATIONS:")
    print("  âœ… GitHub Actions: Git-based CI/CD integration")
    print("  âœ… Jenkins: Traditional CI/CD tool integration")
    print("  âœ… GitLab CI: GitLab-based CI/CD integration")
    print("  âœ… Azure DevOps: Microsoft DevOps integration")
    
    print("\nâš™ï¸ CONFIGURATION:")
    print("  âœ… YAML-based Configuration: Centralized pipeline settings")
    print("  âœ… Environment-specific Settings: Different configs per environment")
    print("  âœ… Customizable Thresholds: Configurable test thresholds")
    print("  âœ… Flexible Stage Configuration: Customizable pipeline stages")
    
    print("\nğŸ¯ PRODUCTION READINESS: READY")
    print("   - Comprehensive testing and validation")
    print("   - Automated deployment with rollback")
    print("   - Security scanning and validation")
    print("   - Full MLOps pipeline integration")
    print("   - Configurable thresholds and stages")
    
    print("\nğŸš€ NEXT STEPS:")
    print("   1. Configure pipeline settings in config/main_config.yaml")
    print("   2. Set up external CI/CD tool integrations")
    print("   3. Configure webhook notifications")
    print("   4. Set up automated pipeline triggers")
    print("   5. Configure deployment environments")

def main():
    """Main demo function."""
    try:
        # Run the main demo
        pipeline = demo_cicd_pipeline()
        
        if pipeline:
            # Show features
            show_cicd_features()
            
            print(f"\nâœ… Demo completed successfully!")
            return pipeline
        else:
            print(f"\nâŒ Demo failed - please check the error messages above")
            return None
            
    except Exception as e:
        print(f"\nâŒ Demo failed with error: {e}")
        print(f"âŒ Demo failed - please check the error messages above")
        return None

if __name__ == "__main__":
    pipeline = main()
